bf16: True
seed: 42
num_train_epochs: 1
per_device_train_batch_size: 4  # 针对单卡 H100 80GB 优化的 batch size
per_device_eval_batch_size: 4
gradient_accumulation_steps: 64  # 保持全局 Batch Size 为 256 (4 * 1 * 64)
evaluation_strategy: "no"
save_strategy: "steps"
save_steps: 10000
learning_rate: 0.0002
weight_decay: 0.
warmup_steps: 100
lr_scheduler_type: "constant_with_warmup"
logging_steps: 1
tf32: True
shuffle: True 
gradient_checkpointing: true
dataloader_num_workers: 4
report_to: wandb
output_dir: ./output/pretrain_single_h100
wandb_project: VoRA
run_name: pretrain_single_h100
deepspeed: ./configs/deepspeed/zero2.json

model:
  llm: Qwen/Qwen2.5-7B-Instruct
  vision_embedding: "AIMv2Embedding"
  patch_size: 14
  image_size: 448
  aux_vision: apple/aimv2-huge-patch14-448
  reuse_aux_vision_embedding_layers: "preprocessor"
  lora:
    layers: 24
    r: 128  # 从 1024 降低到 128，极大减少显存占用
    target_modules: [    
        "self_attn.q_proj",
        "self_attn.k_proj",
        "self_attn.v_proj",
        "self_attn.o_proj",
        "mlp.up_proj",
        "mlp.gate_proj",
        "mlp.down_proj",
    ]

data:
  train:
    data_fetch:
      data_paths: [
        {
          "anno_path": "{data_root}/VoRA-Recap-29M/annotations/VoRA-Recap-29M.json", # 注意：需修改为你的本地路径
          "image_folder": "{data_root}/VoRA-Recap-29M" # 注意：需修改为你的本地路径
        },
        {
          "anno_path": "{data_root}/VoRA-Recap-GLD-1.4M/annotations/VoRA-Recap-GLD-1.4M.json",
          "image_folder": "{data_root}/VVoRA-Recap-GLD-1.4M"
        },
        {
          "anno_path": "{data_root}/VoRA-TextQA-Mixed/annotations/VoRA-TextQA-Mixed.json",
          "image_folder": ""
        },
      ]

    data_preprocess:
      frames_key: frames
      label_key: conversations
      tokenizer: Qwen/Qwen2.5-7B-Instruct
      max_seq_len: 2048
      max_prompt_len: 2048
      vqa_processor_params:
        system_start: "<|im_start|>system\n"
        system_end: "<|im_end|>"
        system_message: "You are a helpful assistant."
        roles: ["\n<|im_start|>user\n", "<|im_end|>\n<|im_start|>assistant\n"]
      num_segments: 1
      frames_ops:
        PILExpand2Square: {}
        HFImageTransform:
          path: apple/aimv2-huge-patch14-448
